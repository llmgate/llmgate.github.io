<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Gate: A Gateway Service for Your LLM Applications</title>
    <link rel="stylesheet" href="style.css">
    <meta property="og:title" content="LLM Gate: A Gateway Service for Your LLM Applications">
    <meta property="og:description" content="A gateway service for your LLM applications">
    <meta property="og:image" content="https://llmgate.github.io/assets/thinking.png">
    <meta property="og:url" content="https://llmgate.github.io">
    <meta name="twitter:card" content="https://llmgate.github.io/assets/thinking.png">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="LLM Gate: A gateway service for your LLM applications">
</head>
<body>

<header>
    <div class="logoText">LLM GATE</div>
</header>

<section id="thinking">
    <img src="assets/thinking.png" alt="Middleman for your LLMs" class="thinkingImage">
    <div>
        <h4>What's this?</h4>
        <p>
            I spent over 3 years at Snap Inc. building a proxy/gateway service for 3D Bitmojis which was the <u>highest paying GPU customer of AWS</u>. The goal of the service was to apply a lot of practices to save cost, improve latency, and ensure high availability while handling over 5 petabytes of data and serving billions of daily requests.
        </p>
        <p>
            Now I want to build a <u>scalable gateway for your LLMs</u> so you can ship faster without worrying about any of these.
        </p>
        <p>
            <a href='https://www.linkedin.com/in/rushijash/'>My LinkedIn</a>
        </p>
        <h4>Interested?</h4>
        <p>
            If you use LLMs in your applications, I want to understand your pain points and solve it for you. Reach out <a href="https://forms.gle/VmioXUmm8FgoWnR37">here</a>.
        </p>
        <h4>A few ideas so far.. (based on User Interviews)</h4>
        <ul>
            <li>Prompt Validation</li>
            <li>Prompt Suggestions</li>
            <li>RAG Integration</li>
            <li>LLM Caching</li>
            <li>LLM Chaining and Fallbacks</li>
            <li>User Authentication, Logging and Learning</li>
            <li>Rate Limiting and Quotas</li>
        </ul>
        <h4>A few use cases...</h4>
        <ul>
            <li>Setup Backend for your WhatsApp bot that uses your product catalog to answer questions</li>
            <li>Setup Backend for your Chrome Extension to cache LLM data per key</li>
            <li>Setup Backend for your mobile app to call multiple llms and receive response in the same format</li>
        </ul>
    </div>
</section>
<section>
    <p>
        Interested in Investing? Reach out <a href="https://forms.gle/AoDETE7quQSBBy1q8">here</a>.
    </p>
</section>
</body>
</html>
